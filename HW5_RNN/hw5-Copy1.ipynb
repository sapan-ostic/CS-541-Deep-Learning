{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "Problem: To memorize the (N-2)th digit for a given sequence of binary numbers.\n",
    "\n",
    "Example: 1 5 2 6 9 2 4 5 6 7 2 \n",
    "\n",
    "Output: 0 0 1 5 2 6 9 2 4 5 6 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-460bcc0eb565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize  # For check_grad, approx_fprime\n",
    "\n",
    "class RNN:\n",
    "    def __init__ (self, numHidden, numInput, numOutput):\n",
    "        self.numHidden = numHidden\n",
    "        self.numInput = numInput\n",
    "        \n",
    "        self.U = np.random.randn(numHidden, numHidden) * 1e-1 # 6x6        \n",
    "        self.V = np.random.randn(numHidden, numInput ) * 1e-1 # 6x1\n",
    "        self.w = np.random.randn(numHidden, numOutput) * 1e-1 # 6x1\n",
    "       \n",
    "        # TODO: IMPLEMENT ME\n",
    "        # forward prop  \n",
    "        self.hidden = np.zeros((numHidden, numInput)) # 6x1\n",
    "        \n",
    "        \n",
    "        # backward prop\n",
    "        self.dU = np.zeros_like(self.U) # 6x6\n",
    "        self.dw = np.zeros_like(self.w) # 6x1\n",
    "        self.dV = np.zeros_like(self.V) # 6x1\n",
    "        self.dhnext = np.zeros_like(self.hidden)\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.learning_rate = 0.0001\n",
    "        \n",
    "    def backward (self, y):\n",
    "        # TODO: IMPLEMENT ME\n",
    "        \n",
    "        for i in reversed(range(self.T)):\n",
    "            dJ_dy = y[i] - self.y_pred[i]  # 1x1\n",
    "            self.dw += np.dot(self.hs[i+1], dJ_dy)\n",
    "\n",
    "            dh = np.dot(self.dw, dJ_dy) + self.dhnext\n",
    "            dhraw = (1 - self.hs[i+1]*self.hs[i+1]) * dh\n",
    "\n",
    "            self.dV += np.dot(dhraw, xs[i].T)\n",
    "\n",
    "            self.dU += np.dot(dhraw, self.hs[i].T)\n",
    "            dhnext = np.dot(self.U.T, dhraw)\n",
    "            \n",
    "            for dparam in [self.U,self.V,self.w]:\n",
    "                np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "            self.U -= self.learning_rate*self.dU\n",
    "            self.V -= self.learning_rate*self.dV\n",
    "            self.w -= self.learning_rate*self.dw        \n",
    "        pass\n",
    "\n",
    "    def forward (self, x):\n",
    "        # TODO: IMPLEMENT ME\n",
    "        self.xs = x\n",
    "        for i in range(self.T):\n",
    "            self.z = np.dot(self.U, self.hs[i]) + np.dot(self.V, x[i]) # 6x1\n",
    "            hidden = np.tanh(self.z) # 6x1\n",
    "            self.y_pred[i] = np.dot(hidden.T, self.w)[0][0] # 1x1\n",
    "            self.hs.append(hidden)   \n",
    "        pass\n",
    "    \n",
    "    def RNNloss(self,y, y_pred):\n",
    "        dy = np.asarray(y_pred) - np.asarray(y)\n",
    "        self.loss = 0.5*np.dot(dy, dy.T)\n",
    "        return self.loss\n",
    "    \n",
    "    def step(self,x, y):\n",
    "        self.T = len(x)\n",
    "        self.y_pred = [0]*self.T\n",
    "        self.hs = []\n",
    "        self.hs.append(self.hidden)\n",
    "        \n",
    "        self.forward(x)\n",
    "        self.backward(y)\n",
    "        loss = self.RNNloss(y, self.y_pred)\n",
    "        print(loss)\n",
    "        return self.y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767\n",
    "def generateData ():\n",
    "    total_series_length = 50\n",
    "    echo_step = 2  # 2-back task\n",
    "    batch_size = 1\n",
    "    x = np.random.choice(2, total_series_length, p=[0.5, 0.5])\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "    y = list(y)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.00339182066314\n",
      "11.505430826429818\n",
      "13.009855523775762\n",
      "12.298281560548954\n",
      "9.998301818246974\n",
      "10.396689608129291\n",
      "9.96819271457521\n",
      "11.787758491288283\n",
      "15.705192069307941\n",
      "7.750082971724172\n",
      "45.17658317579392\n",
      "238.51509055055394\n",
      "758.3681631414016\n",
      "808.5559631526098\n",
      "1212.0751580588442\n",
      "651.4988079952105\n",
      "1010.6637685127316\n",
      "1014.9571736344166\n",
      "1074.8208216583928\n",
      "1165.036120180709\n",
      "1205.985208121261\n",
      "1295.8441828523657\n",
      "1391.0559626822287\n",
      "1465.4195549871315\n",
      "1357.3475020313954\n",
      "1494.6573782269265\n",
      "2110.500228913083\n",
      "2214.638873368896\n",
      "2154.5363026289497\n",
      "10.298931642103781\n",
      "1834.9762009581382\n",
      "14.534531274770124\n",
      "15.005429688131814\n",
      "10.571185959676297\n",
      "13.676916054306133\n",
      "14.123964398284016\n",
      "16.387348313432636\n",
      "13.918305196753195\n",
      "16.2770544768523\n",
      "16.225059788409418\n",
      "21.531996050081446\n",
      "13.429346626414032\n",
      "18.882651969579317\n",
      "23.225048984265975\n",
      "19.792906711887884\n",
      "15.157452374988262\n",
      "22.90389328111518\n",
      "23.85487644945845\n",
      "26.653711061494697\n",
      "27.014842164416383\n",
      "24.582700995396824\n",
      "25.670204658792013\n",
      "32.53308722156905\n",
      "29.187571464500184\n",
      "27.510379301049397\n",
      "25.51403823334968\n",
      "37.29912262539605\n",
      "31.787862398773647\n",
      "36.70921469783592\n",
      "32.51721779411908\n",
      "41.464553962250775\n",
      "38.14469295774629\n",
      "52.874561386518806\n",
      "38.43093884852363\n",
      "41.99187818569938\n",
      "45.47782218180706\n",
      "55.23053328080968\n",
      "64.95056273246477\n",
      "68.41476801849564\n",
      "75.70158124499851\n",
      "66.38235548251258\n",
      "73.8800797459233\n",
      "75.71817862451444\n",
      "67.6312613257872\n",
      "766.460924699604\n",
      "101.83085545869706\n",
      "114.42496741001109\n",
      "109.83268569025228\n",
      "122.43060984996795\n",
      "140.4808740352429\n",
      "126.69498339899515\n",
      "142.73698943522595\n",
      "155.73271922083939\n",
      "170.5116900661976\n",
      "150.3763079144887\n",
      "196.48598541839706\n",
      "207.73500857228325\n",
      "199.5042044942024\n",
      "216.87949432455912\n",
      "232.21707428363263\n",
      "235.26921914403982\n",
      "233.38396404617114\n",
      "263.49028009078296\n",
      "302.6541161947243\n",
      "302.1855864970431\n",
      "298.03119722231907\n",
      "345.1320164030236\n",
      "388.25511273732866\n",
      "373.6945640613321\n",
      "401.47808885046265\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    xs, ys = generateData()\n",
    "    \n",
    "    numHidden = 6\n",
    "    numInput = 1\n",
    "    numTimesteps = len(xs)\n",
    "    rnn = RNN(numHidden, numInput, 1)\n",
    "    \n",
    "    # TODO: IMPLEMENT ME    \n",
    "    for iter in range(100):\n",
    "        xs, ys = generateData()\n",
    "        y_pred, loss = rnn.step(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
